{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the FACE_SUBSCRIPTION_KEY environment variable with your key as the value.\n",
    "# This key will serve all examples in this document.\n",
    "KEY = 'cba050788d4e4e69aa869ee84cb6c9e6'\n",
    "\n",
    "# Set the FACE_ENDPOINT environment variable with the endpoint from your Face service in Azure.\n",
    "# This endpoint will be used in all examples in this quickstart.\n",
    "ENDPOINT = 'https://facialrecognition244.cognitiveservices.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an authenticated FaceClient.\n",
    "\n",
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face ID from john-f-kennedy---mini-biography.jpg :\n",
      "9b2112dc-1e6a-4b86-98c4-0478bd49b675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://www.biography.com/.image/t_share/MTQ1MzAyNzYzOTgxNTE0NTEz/john-f-kennedy---mini-biography.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url)\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Display the detected face ID in the first single-face image.\n",
    "# Face IDs are used for comparison to faces (their IDs) detected in other images.\n",
    "print('Detected face ID from', single_image_name, ':')\n",
    "for face in detected_faces: print (face.face_id)\n",
    "print()\n",
    "\n",
    "# Save this ID for use in Find Similar\n",
    "first_image_face_ID = detected_faces[0].face_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection1.jpg\n",
      "[<azure.cognitiveservices.vision.face.models._models_py3.DetectedFace object at 0x7f5a32e6be20>]\n",
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "# Detect a face in an image that contains a single face\n",
    "single_face_image_url = 'https://raw.githubusercontent.com/Microsoft/Cognitive-Face-Windows/master/Data/detection1.jpg'\n",
    "single_image_name = os.path.basename(single_face_image_url)\n",
    "print(single_image_name)\n",
    "detected_faces = face_client.face.detect_with_url(url=single_face_image_url)\n",
    "print(detected_faces)\n",
    "if not detected_faces:\n",
    "    raise Exception('No face detected from image {}'.format(single_image_name))\n",
    "\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))\n",
    "\n",
    "\n",
    "# Download the image from the url\n",
    "response = requests.get(single_face_image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "print('Drawing rectangle around face... see popup for results.')\n",
    "draw = ImageDraw.Draw(img)\n",
    "for face in detected_faces:\n",
    "    draw.rectangle(getRectangle(face), outline='red')\n",
    "\n",
    "# Display the image in the users default image browser.\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find similar faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect the faces in an image that contains multiple faces\n",
    "# Each detected face gets assigned a new ID\n",
    "multi_face_image_url = \"http://www.historyplace.com/kennedy/president-family-portrait-closeup.jpg\"\n",
    "multi_image_name = os.path.basename(multi_face_image_url)\n",
    "detected_faces2 = face_client.face.detect_with_url(url=multi_face_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through faces detected in group image for the single face from first image.\n",
    "# First, create a list of the face IDs found in the second image.\n",
    "second_image_face_IDs = list(map(lambda x: x.face_id, detected_faces2))\n",
    "# Next, find similar face IDs like the one detected in the first image.\n",
    "similar_faces = face_client.face.find_similar(face_id=first_image_face_ID, face_ids=second_image_face_IDs)\n",
    "if not similar_faces[0]:\n",
    "    print('No similar faces found in', multi_image_name, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar faces found in president-family-portrait-closeup.jpg:\n",
      "  Face ID:  240cd6ab-85c1-4a37-bc6a-e4e4f7cd1121\n",
      "  Face rectangle:\n",
      "    Left:  413\n",
      "    Top:  57\n",
      "    Width:  55\n",
      "    Height:  55\n"
     ]
    }
   ],
   "source": [
    "# Print the details of the similar faces detected\n",
    "print('Similar faces found in', multi_image_name + ':')\n",
    "for face in similar_faces:\n",
    "    first_image_face_ID = face.face_id\n",
    "    # The similar face IDs of the single face image and the group image do not need to match, \n",
    "    # they are only used for identification purposes in each image.\n",
    "    # The similar faces are matched using the Cognitive Services algorithm in find_similar().\n",
    "    face_info = next(x for x in detected_faces2 if x.face_id == first_image_face_ID)\n",
    "    if face_info:\n",
    "        print('  Face ID: ', first_image_face_ID)\n",
    "        print('  Face rectangle:')\n",
    "        print('    Left: ', str(face_info.face_rectangle.left))\n",
    "        print('    Top: ', str(face_info.face_rectangle.top))\n",
    "        print('    Width: ', str(face_info.face_rectangle.width))\n",
    "        print('    Height: ', str(face_info.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in the Person Group Operations,  Snapshot Operations, and Delete Person Group examples.\n",
    "# You can call list_person_groups to print a list of preexisting PersonGroups.\n",
    "# SOURCE_PERSON_GROUP_ID should be all lowercase and alphanumeric. For example, 'mygroupname' (dashes are OK).\n",
    "PERSON_GROUP_ID = 'my-unique-person-group'\n",
    "\n",
    "# Used for the Snapshot and Delete Person Group examples.\n",
    "TARGET_PERSON_GROUP_ID = str(uuid.uuid4()) # assign a random ID (or name it anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person group: my-unique-person-group\n"
     ]
    },
    {
     "ename": "APIErrorException",
     "evalue": "(PersonGroupExists) Person group 'my-unique-person-group' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-93fa1cf0d558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Person group:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mface_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_group_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Define woman friend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/azure/cognitiveservices/vision/face/operations/_person_group_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, person_group_id, name, user_data, recognition_model, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIErrorException\u001b[0m: (PersonGroupExists) Person group 'my-unique-person-group' already exists."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create the PersonGroup\n",
    "'''\n",
    "# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "print('Person group:', PERSON_GROUP_ID)\n",
    "face_client.person_group.create(person_group_id=PERSON_GROUP_ID, name=PERSON_GROUP_ID)\n",
    "\n",
    "# Define woman friend\n",
    "woman = face_client.person_group_person.create(PERSON_GROUP_ID, \"Woman\")\n",
    "# Define man friend\n",
    "man = face_client.person_group_person.create(PERSON_GROUP_ID, \"Man\")\n",
    "# Define child friend\n",
    "child = face_client.person_group_person.create(PERSON_GROUP_ID, \"Child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect faces and register to correct person\n",
    "'''\n",
    "# Find all jpeg images of friends in working directory\n",
    "woman_images = [file for file in glob.glob('*.jpg') if file.startswith(\"woman\")]\n",
    "man_images = [file for file in glob.glob('*.jpg') if file.startswith(\"man\")]\n",
    "child_images = [file for file in glob.glob('*.jpg') if file.startswith(\"child\")]\n",
    "\n",
    "# Add to a woman person\n",
    "for image in woman_images:\n",
    "    w = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, woman.person_id, w)\n",
    "\n",
    "# Add to a man person\n",
    "for image in man_images:\n",
    "    m = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, man.person_id, m)\n",
    "\n",
    "# Add to a child person\n",
    "for image in child_images:\n",
    "    ch = open(image, 'r+b')\n",
    "    face_client.person_group_person.add_face_from_stream(PERSON_GROUP_ID, child.person_id, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the person group...\n",
      "Training status: failed.\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Training the person group has failed.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Training the person group has failed.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train PersonGroup\n",
    "'''\n",
    "print()\n",
    "print('Training the person group...')\n",
    "# Train the person group\n",
    "face_client.person_group.train(PERSON_GROUP_ID)\n",
    "\n",
    "while (True):\n",
    "    training_status = face_client.person_group.get_training_status(PERSON_GROUP_ID)\n",
    "    print(\"Training status: {}.\".format(training_status.status))\n",
    "    print()\n",
    "    if (training_status.status is TrainingStatusType.succeeded):\n",
    "        break\n",
    "    elif (training_status.status is TrainingStatusType.failed):\n",
    "        sys.exit('Training the person group has failed.')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-6b05385c3920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Group image for testing against\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgroup_photo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mIMAGES_FOLDER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Get test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_image_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGES_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_photo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Identify a face against a defined PersonGroup\n",
    "'''\n",
    "# Group image for testing against\n",
    "group_photo = '/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg'\n",
    "IMAGES_FOLDER = os.path.join(os.path.dirname(os.path.realpath(__file__)))\n",
    "# Get test image\n",
    "test_image_array = glob.glob(os.path.join(IMAGES_FOLDER, group_photo))\n",
    "image = open(test_image_array[0], 'r+b')\n",
    "\n",
    "# Detect faces\n",
    "face_ids = []\n",
    "faces = face_client.face.detect_with_stream(image)\n",
    "for face in faces:\n",
    "    face_ids.append(face.face_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def config():\n",
    "#     # Set the FACE_SUBSCRIPTION_KEY environment variable with your key as the value.\n",
    "#     # This key will serve all examples in this document.\n",
    "#     KEY = 'cba050788d4e4e69aa869ee84cb6c9e6'\n",
    "\n",
    "#     # Set the FACE_ENDPOINT environment variable with the endpoint from your Face service in Azure.\n",
    "#     # This endpoint will be used in all examples in this quickstart.\n",
    "#     ENDPOINT = 'https://facialrecognition244.cognitiveservices.azure.com/'\n",
    "#     return KEY, ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# image_path = \"/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg\"\n",
    "# image_data = Image.open(image_path)\n",
    "\n",
    "# image_data.show() \n",
    "\n",
    "# subscription_key, face_api_url = config()\n",
    "\n",
    "# headers = {'Content-Type': 'application/octet-stream',\n",
    "#            'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "# params = {\n",
    "#     'returnFaceId': 'true',\n",
    "#     'returnFaceLandmarks': 'true',\n",
    "#     'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion'\n",
    "# }\n",
    "\n",
    "# response = requests.post(face_api_url, params=params, headers=headers, data= image_data)\n",
    "# # print(response.raise_for_status)\n",
    "# response.raise_for_status()\n",
    "# faces = response.json()\n",
    "\n",
    "# print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659'} \n",
      "\n",
      "RESPONSE:[{'faceId': 'dece0edd-cd1f-444c-b17e-fb8a0c305025', 'faceRectangle': {'top': 335, 'left': 249, 'width': 319, 'height': 319}, 'faceAttributes': {'smile': 1.0, 'headPose': {'pitch': -6.9, 'roll': -4.8, 'yaw': -0.8}, 'gender': 'male', 'age': 39.0, 'facialHair': {'moustache': 0.1, 'beard': 0.1, 'sideburns': 0.1}}}]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import requests\n",
    "\n",
    "\n",
    "KEY = 'cba050788d4e4e69aa869ee84cb6c9e6'\n",
    "# ENDPOINT = 'https://facialrecognition244.cognitiveservices.azure.com/'\n",
    "\n",
    "# Request headers set Subscription key which provides access to this API. Found in your Cognitive Services accounts.\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': KEY,\n",
    "}\n",
    "\n",
    "body = dict()\n",
    "body[\"url\"] = \"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\"\n",
    "\n",
    "body = str(body)\n",
    "print(body, \"\\n\")\n",
    "\n",
    "# Request URL \n",
    "# FaceApiDetect = 'https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair' \n",
    "FaceApiDetect = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair'\n",
    "\n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.json()))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import modules\n",
    "# import requests\n",
    "\n",
    "\n",
    "# KEY = 'cba050788d4e4e69aa869ee84cb6c9e6'\n",
    "# # ENDPOINT = 'https://facialrecognition244.cognitiveservices.azure.com/'\n",
    "\n",
    "# # Request headers set Subscription key which provides access to this API. Found in your Cognitive Services accounts.\n",
    "# headers = {\n",
    "# #     'Content-Type': 'application/json',\n",
    "# #     'Content-Type': 'multipart/form-data',\n",
    "#     'Content-Type': 'image/jpeg',\n",
    "#     'Ocp-Apim-Subscription-Key': KEY\n",
    "    \n",
    "# }\n",
    "\n",
    "# # body = dict()\n",
    "\n",
    "# # path = \"/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg\"\n",
    "# # image_data = Image.open(path)\n",
    "\n",
    "# # body[\"url\"] = \"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\"\n",
    "# # body[\"url\"] = image_data \n",
    "\n",
    "\n",
    "# # files = {\n",
    "# #     'file': (\n",
    "# #         os.path.basename('/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg'), \n",
    "# #         open('/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg', 'rb')\n",
    "# #     ),\n",
    "# #     'Content-Type': 'image/jpeg'\n",
    "# # }\n",
    "\n",
    "# files = {'media': open('/home/furqan/Downloads/datasets/662834_4550818_ertugral_updates.jpg', 'rb')}\n",
    "\n",
    "\n",
    "# # body = str(body)\n",
    "# # print(body, \"\\n\")\n",
    "\n",
    "# # print(image_data)\n",
    "\n",
    "# # Request URL \n",
    "# # FaceApiDetect = 'https://westus.api.cognitive.microsoft.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair' \n",
    "# FaceApiDetect = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair'\n",
    "\n",
    "\n",
    "# try:\n",
    "#     # REST Call \n",
    "#     response = requests.post(FaceApiDetect, files=files, headers=headers) \n",
    "#     print(\"RESPONSE:\" + str(response.json()))\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:409\n"
     ]
    }
   ],
   "source": [
    "personGroupId=\"friends\"\n",
    "\n",
    "body = dict()\n",
    "body[\"name\"] = \"F.R.I.E.N.D.S\"\n",
    "body[\"userData\"] = \"All friends cast\"\n",
    "body = str(body)\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreateLargePersonGroup = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.put(FaceApiCreateLargePersonGroup, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONID: f4a87a3a-aea9-4338-854f-f9b81f80cd6d\n"
     ]
    }
   ],
   "source": [
    "#Request Body\n",
    "body = dict()\n",
    "body[\"name\"] = \"Chandler\"\n",
    "body[\"userData\"] = \"Friends\"\n",
    "body = str(body)\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreatePerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/persons' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiCreatePerson, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[\"personId\"]\n",
    "    print(\"PERSONID: \"+str(personId))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSISTED FACE ID: 9b45e705-92e4-4e39-8fcf-0ae347462830\n",
      "PERSISTED FACE ID: c8b6f35e-55c2-45c8-bd5b-65c61bf2d18b\n",
      "PERSISTED FACE ID: 2dbe632d-d781-4a8c-aaa4-42f200836525\n",
      "PERSISTED FACE ID: 7e14633e-7882-4db8-9701-2b90d2e45f6b\n",
      "PERSISTED FACE ID: 6d6e4127-ac4d-456f-9033-ad405adbbcfe\n"
     ]
    }
   ],
   "source": [
    "# 5 random images of chandler\n",
    "chandlerImageList = [\"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\",\n",
    "                     \"https://i.pinimg.com/236x/b0/57/ff/b057ff0d16bd5205e4d3142e10f03394--muriel-matthew-perry.jpg\",\n",
    "                     \"https://qph.fs.quoracdn.net/main-qimg-74677a162a39c79d6a9aa2b11cc195b1\",\n",
    "                     \"https://pbs.twimg.com/profile_images/2991381736/e2160154f215a325b0fc73f866039311_400x400.jpeg\",\n",
    "                     \"https://i.pinimg.com/236x/f2/9f/45/f29f45049768ddf5c5d75ff37ffbfb3f--hottest-actors-matthew-perry.jpg\"]\n",
    "\n",
    "#Request URL \n",
    "FaceApiCreatePerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/persons/'+personId+'/persistedFaces' \n",
    "\n",
    "for image in chandlerImageList:\n",
    "    body = dict()\n",
    "    body[\"url\"] = image\n",
    "    body = str(body)\n",
    "\n",
    "    try:\n",
    "        # REST Call \n",
    "        response = requests.post(FaceApiCreatePerson, data=body, headers=headers) \n",
    "        responseJson = response.json()\n",
    "        persistedFaceId = responseJson[\"persistedFaceId\"]\n",
    "        print(\"PERSISTED FACE ID: \"+str(persistedFaceId))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:202\n"
     ]
    }
   ],
   "source": [
    "#Request Body\n",
    "body = dict()\n",
    "\n",
    "#Request URL \n",
    "FaceApiTrain = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/train'\n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiTrain, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'requests' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Request Body\n",
    "body = dict()\n",
    "body[\"url\"] = \"https://upload.wikimedia.org/wikipedia/en/thumb/6/6c/Matthew_Perry_as_Chandler_Bing.jpg/220px-Matthew_Perry_as_Chandler_Bing.jpg\"\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiDetect = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true' \n",
    "\n",
    "try:\n",
    "# REST Call \n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    faceId = responseJson[0][\"faceId\"]\n",
    "    print(\"FACE ID: \"+str(faceId))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faceId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-f0acfbb0f784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaceId\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'faceId' is not defined"
     ]
    }
   ],
   "source": [
    "faceId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faceId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-e4ee74149b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfaceIdsList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfaceId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Request Body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"personGroupId\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersonGroupId\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faceId' is not defined"
     ]
    }
   ],
   "source": [
    "faceIdsList = [faceId]\n",
    "\n",
    "# Request Body\n",
    "body = dict()\n",
    "body[\"personGroupId\"] = personGroupId\n",
    "body[\"faceIds\"] = faceIdsList\n",
    "body[\"maxNumOfCandidatesReturned\"] = 1 \n",
    "body[\"confidenceThreshold\"] = 0.5\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiIdentify = 'https://westus.api.cognitive.microsoft.com/face/v1.0/identify' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiIdentify, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[0][\"candidates\"][0][\"personId\"]\n",
    "    confidence = responseJson[0][\"candidates\"][0][\"confidence\"]\n",
    "    print(\"PERSON ID: \"+str(personId)+ \", CONFIDENCE :\"+str(confidence))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Could not detect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is Chandler\n"
     ]
    }
   ],
   "source": [
    "# Request URL \n",
    "FaceApiGetPerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/persons/'+personId\n",
    "\n",
    "try:\n",
    "    response = requests.get(FaceApiGetPerson, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    print(\"This Is \"+str(responseJson[\"name\"]))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
