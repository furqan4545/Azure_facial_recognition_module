{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'cba050788d4e4e69aa869ee84cb6c9e6'\n",
    "ENDPOINT = 'https://facialrecognition244.cognitiveservices.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:[{'faceId': '8cfe04ac-3917-436d-9eff-af1096bedccb', 'faceRectangle': {'top': 335, 'left': 249, 'width': 319, 'height': 319}, 'faceAttributes': {'smile': 1.0, 'headPose': {'pitch': -6.9, 'roll': -4.8, 'yaw': -0.8}, 'gender': 'male', 'age': 39.0, 'facialHair': {'moustache': 0.1, 'beard': 0.1, 'sideburns': 0.1}}}]\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import requests\n",
    "import cv2\n",
    "# Request headers set Subscription key which provides access to this API. Found in\n",
    "# your Cognitive Services accounts.\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Ocp-Apim-Subscription-Key': KEY,\n",
    "}\n",
    "body = dict()\n",
    "img_url = \"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\"\n",
    "img_url2 = \"https://www.stockphotosecrets.com/wp-content/uploads/2016/05/GettyImages-476996143.jpg\"\n",
    "body[\"url\"] = \"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\"\n",
    "body = str(body)\n",
    "# Request URL\n",
    "FaceApiDetect = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true&returnFaceAttributes=age,gender,headPose,smile,facialHair'\n",
    "try:\n",
    "    # REST Call\n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers)\n",
    "    print(\"RESPONSE:\" + str(response.json()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceId': '8cfe04ac-3917-436d-9eff-af1096bedccb', 'faceRectangle': {'top': 335, 'left': 249, 'width': 319, 'height': 319}, 'faceAttributes': {'smile': 1.0, 'headPose': {'pitch': -6.9, 'roll': -4.8, 'yaw': -0.8}, 'gender': 'male', 'age': 39.0, 'facialHair': {'moustache': 0.1, 'beard': 0.1, 'sideburns': 0.1}}}]\n"
     ]
    }
   ],
   "source": [
    "response = response.json()\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8cfe04ac-3917-436d-9eff-af1096bedccb\n",
      "{'top': 335, 'left': 249, 'width': 319, 'height': 319}\n",
      "male\n",
      "1.0\n",
      "39.0\n"
     ]
    }
   ],
   "source": [
    "faceId = response[0][\"faceId\"]\n",
    "print(faceId)\n",
    "faceRectangle = response[0][\"faceRectangle\"]\n",
    "print(faceRectangle)\n",
    "faceAttributes = response[0][\"faceAttributes\"]\n",
    "gender = faceAttributes['gender']\n",
    "print(gender)\n",
    "smile = faceAttributes['smile']\n",
    "print(smile)\n",
    "age = faceAttributes['age']\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there exist multiples facesa or single face. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only single face found\n"
     ]
    }
   ],
   "source": [
    "if len(response) > 1:\n",
    "    print(\"Multiple faces Exist\")\n",
    "else: \n",
    "    print(\"Only single face found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Image object into numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = np.asarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting rectangle against detected face in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faceRectangle[\"left\"]\n",
    "x = faceRectangle[\"left\"]\n",
    "y = faceRectangle[\"top\"]\n",
    "w = faceRectangle[\"width\"]\n",
    "h = faceRectangle[\"height\"]\n",
    "\n",
    "\n",
    "cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)  \n",
    "cv2.imshow('Pic with squares',img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are creating group in which we will store images of different person "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:409\n"
     ]
    }
   ],
   "source": [
    "personGroupId = \"friends\"\n",
    "body = dict()\n",
    "body[\"name\"] = \"F.R.I.E.N.D.S\"\n",
    "body[\"userData\"] = \"All friends cast\"\n",
    "body = str(body)\n",
    "#Request URL\n",
    "FaceApiCreateLargePersonGroup = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId\n",
    "try:\n",
    "    # REST Call\n",
    "    response = requests.put(FaceApiCreateLargePersonGroup, data=body, headers=headers)\n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'F.R.I.E.N.D.S', 'userData': 'All friends cast'}\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are storing the meta data of persons such as name of a person, gender, age etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONID: bcda18cd-873f-48e9-8b8c-14d90998a160\n"
     ]
    }
   ],
   "source": [
    "# Request Body\n",
    "body = dict()\n",
    "body[\"name\"] = \"Chandler\"\n",
    "body[\"userData\"] = \"Friends\"\n",
    "body = str(body)\n",
    "# Request URL\n",
    "FaceApiCreatePerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId + '/persons'\n",
    "try:\n",
    "    # REST Call\n",
    "    response = requests.post(FaceApiCreatePerson, data=body, headers=headers)\n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[\"personId\"]\n",
    "    print(\"PERSONID: \" + str(personId))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Providing multiples images of different persons\n",
    "### We are storing 5 images of each person in the personGroups so that later on we can train a model on the detected faces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='facialrecognition244.cognitiveservices.azure.com', port=443): Max retries exceeded with url: /face/v1.0/persongroups/friends/persons/bcda18cd-873f-48e9-8b8c-14d90998a160/persistedFaces (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb4a50020d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "HTTPSConnectionPool(host='facialrecognition244.cognitiveservices.azure.com', port=443): Max retries exceeded with url: /face/v1.0/persongroups/friends/persons/bcda18cd-873f-48e9-8b8c-14d90998a160/persistedFaces (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb4a5002f70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "HTTPSConnectionPool(host='facialrecognition244.cognitiveservices.azure.com', port=443): Max retries exceeded with url: /face/v1.0/persongroups/friends/persons/bcda18cd-873f-48e9-8b8c-14d90998a160/persistedFaces (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb4a50020d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "HTTPSConnectionPool(host='facialrecognition244.cognitiveservices.azure.com', port=443): Max retries exceeded with url: /face/v1.0/persongroups/friends/persons/bcda18cd-873f-48e9-8b8c-14d90998a160/persistedFaces (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb4a5002f70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n",
      "HTTPSConnectionPool(host='facialrecognition244.cognitiveservices.azure.com', port=443): Max retries exceeded with url: /face/v1.0/persongroups/friends/persons/bcda18cd-873f-48e9-8b8c-14d90998a160/persistedFaces (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fb4a50027f0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))\n"
     ]
    }
   ],
   "source": [
    "# 5 random images of chandler\n",
    "chandlerImageList = [\"http://www.imagozone.com/var/albums/vedete/Matthew%20Perry/Matthew%20Perry.jpg?m=1355670659\",\n",
    "\"https://i.pinimg.com/236x/b0/57/ff/b057ff0d16bd5205e4d3142e10f03394--muriel-matthew-perry.jpg\",\n",
    "\"https://qph.fs.quoracdn.net/main-qimg-74677a162a39c79d6a9aa2b11cc195b1\",\n",
    "\"https://pbs.twimg.com/profile_images/2991381736/e2160154f215a325b0fc73f866039311_400x400.jpeg\",\n",
    "\"https://i.pinimg.com/236x/f2/9f/45/f29f45049768ddf5c5d75ff37ffbfb3f--hottest-actors-matthew-perry.jpg\"]\n",
    "\n",
    "joeyImageList = [\n",
    "   \"https://upload.wikimedia.org/wikipedia/en/d/da/Matt_LeBlanc_as_Joey_Tribbiani.jpg\",\n",
    "    \"https://a1cf74336522e87f135f-2f21ace9a6cf0052456644b80fa06d4f.ssl.cf2.rackcdn.com/images/characters_opt/p-friends-matt-leblanc.jpg\",\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/X_217c5312.jpg/220px-X_217c5312.jpg\",\n",
    "    \"https://media3.s-nbcnews.com/j/newscms/2018_26/1349761/matt-leblanc-joey-friends-today-180629-tease_e00b0cfeb43333656f5334f3ea892fe8.social_share_1200x630_center.jpg\",\n",
    "    \"https://i.pinimg.com/originals/d0/61/02/d061022a20400c1e2db1ce197bc8e64a.jpg\"\n",
    "]\n",
    "\n",
    "# Request URL\n",
    "FaceApiCreatePerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/' + personGroupId + '/persons/' + personId + '/persistedFaces'\n",
    "\n",
    "for image in chandlerImageList:\n",
    "    body = dict()\n",
    "    body[\"url\"] = image\n",
    "    body = str(body)\n",
    "    try:\n",
    "        # REST Call\n",
    "        response = requests.post(FaceApiCreatePerson, data=body, headers=headers)\n",
    "        responseJson = response.json()\n",
    "        persistedFaceId = responseJson[\"persistedFaceId\"]\n",
    "        print(\"PERSISTED FACE ID: \" + str(persistedFaceId))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "### Here we are doing training on provided face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE:202\n"
     ]
    }
   ],
   "source": [
    "#Request Body\n",
    "body = dict()\n",
    "\n",
    "#Request URL \n",
    "FaceApiTrain = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/train'\n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiTrain, data=body, headers=headers) \n",
    "    print(\"RESPONSE:\" + str(response.status_code))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect face \n",
    "### Here We are passing the image to get the face coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACE ID: 51392e07-3b8f-4ba3-9a96-e0b836e0c534\n"
     ]
    }
   ],
   "source": [
    "# Request Body\n",
    "body = dict()\n",
    "body[\"url\"] = \"https://vignette.wikia.nocookie.net/friends/images/9/99/Season_2_chandler.png/revision/latest/scale-to-width-down/340?cb=20200326151017\"\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiDetect = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/detect?returnFaceId=true' \n",
    "\n",
    "try:\n",
    "# REST Call \n",
    "    response = requests.post(FaceApiDetect, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    faceId = responseJson[0][\"faceId\"]\n",
    "    print(\"FACE ID: \"+str(faceId))\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing face\n",
    "\n",
    "### Now here we will compute similarity score between the provided face and the stored faces in person group and the face that matches with the queried face will return its ID and a similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON ID: bcda18cd-873f-48e9-8b8c-14d90998a160, CONFIDENCE :0.65836\n"
     ]
    }
   ],
   "source": [
    "faceIdsList = [faceId]\n",
    "\n",
    "# Request Body\n",
    "body = dict()\n",
    "body[\"personGroupId\"] = personGroupId\n",
    "body[\"faceIds\"] = faceIdsList\n",
    "body[\"maxNumOfCandidatesReturned\"] = 1 \n",
    "body[\"confidenceThreshold\"] = 0.5\n",
    "body = str(body)\n",
    "\n",
    "# Request URL \n",
    "FaceApiIdentify = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/identify' \n",
    "\n",
    "try:\n",
    "    # REST Call \n",
    "    response = requests.post(FaceApiIdentify, data=body, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    personId = responseJson[0][\"candidates\"][0][\"personId\"]\n",
    "    confidence = responseJson[0][\"candidates\"][0][\"confidence\"]\n",
    "    print(\"PERSON ID: \"+str(personId)+ \", CONFIDENCE :\"+str(confidence))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Could not detect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, retrieve a person’s name and userData representing the registered person face image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Is Chandler\n"
     ]
    }
   ],
   "source": [
    "# Request URL \n",
    "FaceApiGetPerson = 'https://facialrecognition244.cognitiveservices.azure.com/face/v1.0/persongroups/'+personGroupId+'/persons/'+personId\n",
    "\n",
    "try:\n",
    "    response = requests.get(FaceApiGetPerson, headers=headers) \n",
    "    responseJson = response.json()\n",
    "    print(\"This Is \"+str(responseJson[\"name\"]))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data stored against the person Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personId': 'bcda18cd-873f-48e9-8b8c-14d90998a160',\n",
       " 'persistedFaceIds': ['7205c8fc-0a0a-4dbe-8530-7339ebbc28c6',\n",
       "  '7406e56f-11ae-4056-a58a-321ae68b8297',\n",
       "  '96dda81f-9a6b-474c-adaa-645c83ba26e3',\n",
       "  'c840dafb-c794-41c6-b629-0b302d1b8020',\n",
       "  'fc180b57-75c3-4af9-86d5-ad0c9d71f121'],\n",
       " 'name': 'Chandler',\n",
       " 'userData': 'Friends'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responseJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END HERE\n",
    "....................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFont\n",
    "\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing rectangle around face... see popup for results.\n"
     ]
    }
   ],
   "source": [
    "face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "detected_faces = face_client.face.detect_with_url(url=img_url2)\n",
    "\n",
    "# Download the image from the url\n",
    "response = requests.get(img_url2)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# For each face returned use the face rectangle and draw a red box.\n",
    "print('Drawing rectangle around face... see popup for results.')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "\n",
    "for face in detected_faces:\n",
    "    font = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 20)\n",
    "    draw.text((50, 0), \"Helo\", (255, 255, 255), font=font)\n",
    "    draw.rectangle(getRectangle(face), outline='red',  width=10)\n",
    "    \n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
